{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook formats the data, and runs it through our bidirectional transformer architecture.\n",
    "\n",
    "### Data formatting:\n",
    "\n",
    "Refer to this notebook: https://github.com/ocatak/lstm_malware_detection/blob/master/deep_learnin_lstm_malware_detection.ipynb\n",
    "\n",
    "### Bidirectional architecture:\n",
    "\n",
    "... to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './keras_bert_rec')\n",
    "import importlib\n",
    "import keras_bert_rec as rec\n",
    "importlib.reload(rec)\n",
    "\n",
    "import argparse\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "\n",
    "from itertools import chain\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_bert\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n",
      "Requirement already satisfied: numpy in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras_bert) (1.19.1)\n",
      "Collecting Keras>=2.4.3 (from keras_bert)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: keras-transformer>=0.38.0 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras_bert) (0.38.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from Keras>=2.4.3->keras_bert) (1.5.2)\n",
      "Requirement already satisfied: h5py in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from Keras>=2.4.3->keras_bert) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from Keras>=2.4.3->keras_bert) (5.3.1)\n",
      "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras-transformer>=0.38.0->keras_bert) (0.14.0)\n",
      "Requirement already satisfied: keras-multi-head>=0.27.0 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras-transformer>=0.38.0->keras_bert) (0.27.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras-transformer>=0.38.0->keras_bert) (0.6.0)\n",
      "Requirement already satisfied: keras-pos-embd>=0.11.0 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras-transformer>=0.38.0->keras_bert) (0.11.0)\n",
      "Requirement already satisfied: keras-embed-sim>=0.8.0 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras-transformer>=0.38.0->keras_bert) (0.8.0)\n",
      "Requirement already satisfied: six in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from h5py->Keras>=2.4.3->keras_bert) (1.15.0)\n",
      "Requirement already satisfied: keras-self-attention==0.46.0 in /home/serena/.cache/pypoetry/virtualenvs/cyberbert-m_DSUQKG-py3.7/lib/python3.7/site-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras_bert) (0.46.0)\n",
      "Building wheels for collected packages: keras-bert\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/serena/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n",
      "Successfully built keras-bert\n",
      "Installing collected packages: Keras, keras-bert\n",
      "  Found existing installation: Keras 2.2.3\n",
      "    Uninstalling Keras-2.2.3:\n",
      "      Successfully uninstalled Keras-2.2.3\n",
      "Successfully installed Keras-2.4.3 keras-bert-0.86.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "## Calls\n",
    "malware_calls_df = pd.read_csv(f\"{DATA_PATH}calls.zip\", compression=\"zip\",\n",
    "                               sep=\"\\t\", names=[\"API_Calls\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labels (\"types\")\n",
    "malware_labels_df = pd.read_csv(f\"{DATA_PATH}types.zip\", compression=\"zip\",\n",
    "                               sep=\"\\t\", names=[\"API_Labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concat data\n",
    "malware_calls_df[\"API_Labels\"] = malware_labels_df.API_Labels\n",
    "malware_calls_df[\"API_Calls\"] = malware_calls_df.API_Calls.apply(lambda x: \" \".join(x.split(\",\")))\n",
    "\n",
    "malware_calls_df[\"API_Labels\"] = malware_calls_df.API_Labels.apply(lambda x: 1 if x == \"Virus\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 800\n",
    "max_len = 100\n",
    "\n",
    "X = malware_calls_df.API_Calls\n",
    "Y = malware_calls_df.API_Labels.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SpatialDropout1D\n",
    "# from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_calls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X)\n",
    "print('Found %s unique tokens.' % len(tok.word_index))\n",
    "X = tok.texts_to_sequences(X.values)\n",
    "X = sequence.pad_sequences(X, maxlen=max_len)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.15)\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y_train_enc = le.fit_transform(Y_train)\n",
    "Y_train_enc = np_utils.to_categorical(Y_train_enc)\n",
    "\n",
    "Y_test_enc = le.transform(Y_test)\n",
    "Y_test_enc = np_utils.to_categorical(Y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyberbert",
   "language": "python",
   "name": "cyberbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
